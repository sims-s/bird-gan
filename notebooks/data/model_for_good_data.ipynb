{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pprint\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label data we want to keep\n",
    "## Bird labeling criteria:\n",
    "* A bird is good if it is not bad\n",
    "* A bird is bad if:\n",
    "    * It's flying\n",
    "    * It's swimming\n",
    "    * It contains complex branches, even in background (don't need the gan to learn anything this facny)\n",
    "        * Sometimes bird is sitting on branch, that's OK\n",
    "        * Background is blurred means its a non issue\n",
    "    * It's camoflauged\n",
    "    * There are multiple birds\n",
    "    * There are objects unrelated to the bird (e.g. human hand)\n",
    "    * Parts of the bird are missing\n",
    "        * to be good, need to see Most of head, beak, body, tail\n",
    "    * The bird is oriented in a non-standard way (e.g. upsidedown)\n",
    "        * Bird should be approximatley head -> body -> tail (top to bottom)\n",
    "        * Bird shouldn't be mostly vertical\n",
    "        * Bird feet should be on a horiztonally flatish surface (e.g. not standing on the side of the image)\n",
    "        * Bird should be facing forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Label the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = '../../data/first_pass/quality_labels.json'\n",
    "with open(label_path, 'r') as f:\n",
    "    labels = json.load(f)\n",
    "possible_labels = list(labels.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell for reviewing labels\n",
    "# start_idx = 0\n",
    "# for i in range(start_idx, 1500):\n",
    "#     img = Image.open('../../data/first_pass/images/%d.jpg'%i)\n",
    "#     plt.imshow(img)\n",
    "#     cls = \"greg\"\n",
    "#     for k, v in labels.items():\n",
    "#         if i in v:\n",
    "#             cls = k\n",
    "#     plt.title('%d, %s'%(i, cls))\n",
    "    \n",
    "#     plt.show()\n",
    "#     res = input()\n",
    "#     if res.lower()=='break': break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yay stackoerflow! https://stackoverflow.com/questions/2460177/edit-distance-in-python\n",
    "def levenshteinDistance(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell for labeling the data. Just look @ images in windows explorer - infinitely easeir\n",
    "\n",
    "# for i in range(0):\n",
    "#     if any([i in v for _, v in labels.items()]): continue\n",
    "#     print(i)\n",
    "#     res = input()\n",
    "#     if res=='exit': break\n",
    "#     labels[min(possible_labels, key = partial(levenshteinDistance, res))].append(i)\n",
    "# with open(label_path, 'w') as f:\n",
    "#     json.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../data/first_pass/'\n",
    "image_path = data_path + 'images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_skip_none(batch):\n",
    "    def none_check(item):\n",
    "        if hasattr(item, '__iter__'):\n",
    "            return all([i is not None for i in item])\n",
    "        return item is not None\n",
    "    batch = list(filter(none_check, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_for_epoch(model, loader, loss_fn, opt):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    pbar = tqdm(total = len(loader), leave=False)\n",
    "    for batch_imgs, batch_labels in loader:\n",
    "        opt.zero_grad()\n",
    "        batch_imgs, batch_labels = batch_imgs.to(device), batch_labels.to(device)\n",
    "        pred = model(batch_imgs)\n",
    "        loss = loss_fn(pred, batch_labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    return np.mean(losses)\n",
    "\n",
    "def test_for_epoch(model, loader, loss_fn, n_classes, thresh=.5):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(total = len(loader), leave=False)\n",
    "        for batch_imgs, batch_labels in loader:\n",
    "            batch_imgs, batch_labels = batch_imgs.to(device), batch_labels.to(device)\n",
    "            batch_preds = model(batch_imgs)\n",
    "            loss_val = loss_fn(batch_preds, batch_labels)\n",
    "            losses.append(loss_val.item())\n",
    "            preds.append(torch.softmax(batch_preds, dim=-1).data.cpu().numpy())\n",
    "            labels.append(np.eye(n_classes)[batch_labels.data.cpu().numpy()])\n",
    "            pbar.update(1)\n",
    "        pbar.close()    \n",
    "    \n",
    "    preds = np.vstack(preds)\n",
    "    labels = np.vstack(labels)\n",
    "    if n_classes==2:\n",
    "        pred_class = (preds[:,1] > thresh).astype(np.int)\n",
    "    else:\n",
    "        pred_class = np.argmax(preds, axis=1)\n",
    "    label_class = np.argmax(labels, axis=1)\n",
    "    \n",
    "    metrics = {}\n",
    "    for i in range(n_classes):\n",
    "        this_auc = roc_auc_score((labels[:,i]==1).astype(np.int), preds[:,i])\n",
    "        this_acc = np.mean(pred_class[label_class==i]==label_class[label_class==i])\n",
    "        metrics[i] = {'auc' : this_auc, 'conditional_acc': this_acc}\n",
    "    \n",
    "    metric_df = pd.DataFrame.from_dict(metrics, orient='index').reset_index(drop=True)\n",
    "    metric_df.rename({'index' : 'class_id', 0: \"auc\", 1: \"conditional_acc\"}, axis=1, inplace=True)\n",
    "    return np.mean(losses), metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "inverse_normalize_transform = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "   std=[1/0.229, 1/0.224, 1/0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['good', 'flying', 'swimming', 'branches', 'camoflauge', 'multiple', 'objects', 'orientation', 'missing'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_key_mapper = {k : 1 if k==\"multiple\" else 0 for i, k in enumerate(labels.keys())}\n",
    "num_classes = len(set(list(label_key_mapper.values())))\n",
    "n_labeled = sum([len(v) for _, v in labels.items()])\n",
    "img_id_to_class = {i : label_key_mapper[k] for k, v in labels.items() for i in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1025\n",
       "1     123\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(img_id_to_class, orient='index')[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {}\n",
    "test_dict = {}\n",
    "train_counter = 0\n",
    "test_counter = 0\n",
    "for i in img_id_to_class.keys():\n",
    "    if np.random.rand() < .8:\n",
    "        train_dict[train_counter] = {'img' : i, 'class': img_id_to_class[i]}\n",
    "        train_counter+=1\n",
    "    else:\n",
    "        test_dict[test_counter] = {'img' : i, 'class': img_id_to_class[i]}\n",
    "        test_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.894019\n",
       "1    0.105981\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series({k: v['class'] for k, v in train_dict.items()}).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.887179\n",
       "1    0.112821\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series({k: v['class'] for k, v in test_dict.items()}).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the daataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelQualityDataset(Dataset):\n",
    "    def __init__(self, data_dictionary, load_path, transforms=None):\n",
    "        self.data = data_dictionary\n",
    "        self.load_path = load_path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = Image.open(image_path + '%d.jpg'%self.data[idx]['img'])\n",
    "        except FileNotFoundError:\n",
    "            return None, None\n",
    "        label = self.data[idx]['class']\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LabelQualityDataset(train_dict, image_path, train_transforms)\n",
    "test_dataset = LabelQualityDataset(test_dict, image_path, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_count_show = 10\n",
    "shown_dict = {i : 0 for i in range(n_classes)}\n",
    "for batch_imgs, batch_labels in train_dataloader:\n",
    "    if not np.sum(batch_labels.data.cpu().numpy()): continue\n",
    "    for img, l in zip(batch_imgs, batch_labels):\n",
    "        if shown_dict[l.item()]>=class_count_show: continue\n",
    "        img = inverse_normalize_transform(img).permute(1,2,0)\n",
    "        plt.imshow(img.data.cpu().numpy())\n",
    "        plt.title(l.item())\n",
    "        plt.show()\n",
    "        shown_dict[l.item()]+=1\n",
    "    if all([v>=class_count_show for _, v in shown_dict.items()]): break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, n_classes)\n",
    "resnet.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight = torch.tensor([1.,2.]).to(device))\n",
    "opt = optim.Adam(resnet.fc.parameters())\n",
    "opt_full = optim.Adam(resnet.parameters(), lr=10**-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Different models used different just_head_steps vs not that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_head_steps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nb_epochs = 4\n",
    "for i in range(nb_epochs):\n",
    "    if i < just_head_steps:\n",
    "        train_loss = train_for_epoch(resnet, train_dataloader, loss_fn, opt)\n",
    "    else:\n",
    "        train_loss = train_for_epoch(resnet, train_dataloader, loss_fn, opt_full)\n",
    "    print('mean train loss: %.4f'%train_loss)\n",
    "    test_loss, metric_df = test_for_epoch(resnet, test_dataloader, loss_fn, n_classes, thresh=.5)\n",
    "    test_auc = metric_df.iloc[1]['auc']\n",
    "    display(metric_df)\n",
    "    print('mean test loss: %.4f'%test_loss)\n",
    "    print('='*100)\n",
    "#     if test_auc > .9:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet.load_state_dict(torch.load('missing_predictor.pt'))\n",
    "# display(test_for_epoch(resnet, test_dataloader, loss_fn, 2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), 'multiple_predictor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Use the models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../models/final_filter_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    resnet = models.resnet18()\n",
    "    resnet.fc = nn.Linear(resnet.fc.in_features, 2)\n",
    "    resnet.to(device)\n",
    "    resnet.load_state_dict(torch.load(model_path + model_name))\n",
    "    return resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, max_val, load_path, transforms):\n",
    "        self.max_val = max_val\n",
    "        self.load_path = load_path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img = Image.open(image_path + '%d.jpg'%idx)\n",
    "        except FileNotFoundError:\n",
    "            return None, None\n",
    "        \n",
    "        img = self.transforms(img)\n",
    "        return img, idx\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = max([int(img_id[:-4]) for img_id in os.listdir(image_path)])\n",
    "unlabeled_dataset = UnlabeledDataset(max_val, image_path, test_transforms)\n",
    "unlabeled_dataloader = DataLoader(unlabeled_dataset, batch_size=32, collate_fn = collate_skip_none, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for evaluating picking evaluating threshholds\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     pbar = tqdm(total = len(unlabeled_dataloader), leave=False)\n",
    "#     for batch, _ in unlabeled_dataloader:\n",
    "#         batch = batch.to(device)\n",
    "#         pred = torch.softmax(resnet(batch), dim=-1).data.cpu().numpy()\n",
    "#         show_indexer = pred[:,1]>pred_thresh\n",
    "#         for p, img in zip(pred[show_indexer,1], batch[show_indexer]):\n",
    "# #             if p > .4: continue\n",
    "#             print(p)\n",
    "#             img = inverse_normalize_transform(img).permute(1,2,0).data.cpu().numpy()\n",
    "#             plt.imshow(img)\n",
    "#             plt.show()\n",
    "#         pbar.update(1)\n",
    "#     pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_threshes = {\n",
    "    \"branches_predictor.pt\" : .6,\n",
    "    \"camo_predictor.pt\" : .5,\n",
    "    \"flying_predictor.pt\" : .4,\n",
    "    \"missing_predictor.pt\" : .4,\n",
    "    \"multiple_predictor.pt\" : .65,\n",
    "    \"object_predictor.pt\" : .5,\n",
    "    \"orientation_predictor.pt\" : .3, \n",
    "    \"swimming_predictor.pt\" : .35,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5340), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5340), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5340), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5340), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5340), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5340), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5340), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5340), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "should_skip = {}\n",
    "outer_pbar = tqdm(total = len(pred_threshes), leave=False)\n",
    "for model_name, thresh in pred_threshes.items():\n",
    "    model = load_model(model_name)\n",
    "    with torch.no_grad():\n",
    "        inner_pbar = tqdm(total = len(unlabeled_dataloader), leave=False)\n",
    "        predicted_imgs = []\n",
    "        for batch, idx in unlabeled_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            pred = torch.softmax(model(batch), dim=-1).data.cpu().numpy()[:,1]\n",
    "            predicted_indicies = idx[pred > thresh].data.cpu().numpy().ravel()\n",
    "            predicted_imgs.append(predicted_indicies)\n",
    "            inner_pbar.update(1)\n",
    "        should_skip[model_name] = np.hstack(predicted_imgs)\n",
    "        inner_pbar.close()\n",
    "    outer_pbar.update(1)\n",
    "outer_pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23792, 2248, 12216, 6425, 3991, 1741, 14290, 8900]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(v) for _, v in should_skip.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(o):\n",
    "    if isinstance(o, np.generic): return o.item() \n",
    "    elif isinstance(o, np.ndarray): return list(o)\n",
    "    raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('should_skip.json', 'w') as f:\n",
    "    json.dump(should_skip, f, default=convert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Move the data around! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../../data/modeling_256/'\n",
    "save_img_dir = save_dir + 'images/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "if not os.path.exists(save_img_dir):\n",
    "    os.mkdir(save_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('should_skip.json', 'r') as f:\n",
    "    should_skip = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_copy = set(list(itertools.chain(*[v for _,v in should_skip.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66938"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dont_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68a7e067bdf45d7b01bdc18bf307a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=103062), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copy the results!\n",
    "id_counter = 0\n",
    "pbar = tqdm(total = 170000 - len(dont_copy))\n",
    "for f in os.listdir(image_path):\n",
    "    index = int(f[:-4])\n",
    "    if index in dont_copy:\n",
    "        continue\n",
    "    save_img_path = save_img_dir + '%d.jpg'%id_counter\n",
    "    if os.path.exists(save_img_path):\n",
    "        id_counter +=1\n",
    "        continue\n",
    "    copyfile(image_path + f, save_img_path)\n",
    "    id_counter +=1\n",
    "    \n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
